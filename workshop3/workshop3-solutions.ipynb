{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exercise: House price levels and dispersion\n",
    "\n",
    "For this exercise, we're using data on around 1,500 observations of house prices and house characteristics from Ames, a small city in Iowa.\n",
    "\n",
    "1. Load the Ames housing data set from `ames_houses.csv` located in the `data/` folder. \n",
    "2. Restrict the data to the columns `SalePrice` and `Neighborhood`.\n",
    "3. Check that there are no observations with missing values in this data.\n",
    "4. Compute the average house price (column `SalePrice`) by neighborhood (column `Neighborhood`). List the three most expensive neighborhoods, for example by using [`sort_values()`](https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.sort_values.html).\n",
    "5. You are interested to quantify the price dispersion in each neighborhood. To this end, compute the standard deviation by neighborhood using [`std()`](https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.std.html). Which are the three neighborhoods with the most dispersed prices?\n",
    "6. An alternative measure of dispersion is the ratio of the 90th and 10th percentile of the house price distribution. Use the [`quantile()`](https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.quantile.html) method to compute the P90 and P10 statistics by neighborhood, compute their ratio and print the three neighborhoods with the largest dispersion.\n",
    "\n",
    "    *Hint:* The `quantile()` function takes _quantiles_ as arguments, i.e., instead of the 90th percentile you need to specify the quantile as 0.9."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Solution"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Part (1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Uncomment this to use files in the local data/ directory\n",
    "DATA_PATH = '../data'\n",
    "\n",
    "# Uncomment this to load data directly from GitHub\n",
    "# DATA_PATH = 'https://raw.githubusercontent.com/richardfoltyn/TECH2-H24/main/data'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Path to Ames housing CSV file\n",
    "fn = f'{DATA_PATH}/ames_houses.csv'\n",
    "\n",
    "# Read in file\n",
    "df = pd.read_csv(fn)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Part (2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Keep only the columns SalePrice and Neighborhood\n",
    "df = df[['SalePrice', 'Neighborhood']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Part (3)\n",
    "\n",
    "To check whether there are any missing values, we can for example use `info()`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of observations: 1,460\n",
      "\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 1460 entries, 0 to 1459\n",
      "Data columns (total 2 columns):\n",
      " #   Column        Non-Null Count  Dtype  \n",
      "---  ------        --------------  -----  \n",
      " 0   SalePrice     1460 non-null   float64\n",
      " 1   Neighborhood  1460 non-null   object \n",
      "dtypes: float64(1), object(1)\n",
      "memory usage: 22.9+ KB\n"
     ]
    }
   ],
   "source": [
    "N = len(df)\n",
    "print(f'Total number of observations: {N:,d}\\n')\n",
    "\n",
    "# Print number of non-missing observations\n",
    "df.info(show_counts=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since the number of non-missing observations is the same as the number of total observations, there are no missing values in the data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Part (4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Neighborhood\n",
       "Blmngtn    194870.882353\n",
       "Blueste    137500.000000\n",
       "BrDale     104493.750000\n",
       "BrkSide    124834.051724\n",
       "ClearCr    212565.428571\n",
       "CollgCr    197965.773333\n",
       "Crawfor    210624.725490\n",
       "Edwards    128219.700000\n",
       "Gilbert    192854.506329\n",
       "IDOTRR     100123.783784\n",
       "Name: SalePrice, dtype: float64"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Group data by neighborhood\n",
    "groups = df.groupby('Neighborhood')\n",
    "\n",
    "# Compute mean house price by neighborhood\n",
    "mean_price = groups['SalePrice'].mean()\n",
    "\n",
    "# Print first 10 entries\n",
    "mean_price.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "These means are not sorted, so we have to use `sort_values()` to sort them.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Neighborhood\n",
       "NoRidge    335295.317073\n",
       "NridgHt    316270.623377\n",
       "StoneBr    310499.000000\n",
       "Name: SalePrice, dtype: float64"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Sort in descending order, with highest values on top\n",
    "mean_price = mean_price.sort_values(ascending=False)\n",
    "\n",
    "# Print the 3 neighborhoods with the highest average price\n",
    "mean_price.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If we are not interested in any of the intermediate objects, we can chain all these operations into a single line as follows:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Neighborhood\n",
       "NoRidge    335295.317073\n",
       "NridgHt    316270.623377\n",
       "StoneBr    310499.000000\n",
       "Name: SalePrice, dtype: float64"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Print the 3 neighborhoods with the most expensive average price\n",
    "df.groupby('Neighborhood')['SalePrice'].mean().sort_values(ascending=False).head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Part (5)\n",
    "\n",
    "Computing the standard deviation and sorting in descending order is performed in exactly the same way as for the mean, so we just adapt the last line:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Neighborhood\n",
       "NoRidge    121412.658640\n",
       "StoneBr    112969.676640\n",
       "NridgHt     96392.544954\n",
       "Name: SalePrice, dtype: float64"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Print the 3 neighborhoods with the most expensive average price\n",
    "df.groupby('Neighborhood')['SalePrice'].std().sort_values(ascending=False).head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Part (6)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We first compute the P90 and P10 separately, then compute their ratio and sort the results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Neighborhood\n",
       "Blmngtn    1.453749\n",
       "Blueste    1.170481\n",
       "BrDale     1.395617\n",
       "BrkSide    2.309796\n",
       "ClearCr    1.835535\n",
       "Name: SalePrice, dtype: float64"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Compute the 90th percentile of house prices by neighborhood\n",
    "P90 = df.groupby('Neighborhood')['SalePrice'].quantile(0.9)\n",
    "\n",
    "# Compute the 10th percentile of house prices by neighborhood\n",
    "P10 = df.groupby('Neighborhood')['SalePrice'].quantile(0.1)\n",
    "\n",
    "# Compute ratio of percentiles, P90/P10\n",
    "P90_P10 = P90 / P10\n",
    "\n",
    "# Print first 5 entries (unsorted)\n",
    "P90_P10.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Neighborhood\n",
       "IDOTRR     2.546182\n",
       "StoneBr    2.533834\n",
       "BrkSide    2.309796\n",
       "Name: SalePrice, dtype: float64"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Sort values in descending order and print the top 3 neighborhoods\n",
    "P90_P10.sort_values(ascending=False).head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With the help of a lambda expression, we can also directly compute the P90/P10 ratio in a single operation as follows:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Neighborhood\n",
       "IDOTRR     2.546182\n",
       "StoneBr    2.533834\n",
       "BrkSide    2.309796\n",
       "Name: SalePrice, dtype: float64"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Compute P90/P10 and sort in a single line\n",
    "df.groupby('Neighborhood')['SalePrice'].agg(lambda x: x.quantile(0.9) / x.quantile(0.1)).sort_values(ascending=False).head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "# Exercise: Determinants of house prices\n",
    "\n",
    "For this exercise, we're using data on around 1,500 observations of house prices and house characteristics from Ames, a small city in Iowa.\n",
    "\n",
    "1.  Load the Ames housing data set from `ames_houses.csv` located in the `data/` folder. \n",
    "2.  Restrict the data to the columns `SalePrice`, `LotArea` and `Bedrooms`.\n",
    "3.  Restrict your data set to houses with one or more bedrooms and a lot area of at least 100m².\n",
    "4.  Compute the average lot area. Create a new column `LargeLot` which takes on the value of 1 if the lot area is above the average (_\"large\"_), and 0 otherwise (_\"small\"_). \n",
    "\n",
    "    What is the average lot area within these two categories?\n",
    "5.  Create a new column `Rooms` which categorizes the number of `Bedrooms` into three groups: 1, 2, and 3 or more. You can create these categories using boolean indexing, [`np.where()`](https://numpy.org/doc/2.0/reference/generated/numpy.where.html), pandas's [`where()`](https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.where.html), or some other way.\n",
    "6.  Compute the mean `SalePrice` within each group formed by `LargeLot` and `Rooms` (for a total of 6 different categories) using [`groupby()`](https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.groupby.html).\n",
    "7.  Compute and report the average price difference between 1 and 2 bedrooms for a house with a small lot area.\n",
    "8.  Compute and report the average price difference between a small and a large lot for a house with 2 bedrooms."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Solution"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Part (1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Uncomment this to use files in the local data/ directory\n",
    "DATA_PATH = '../data'\n",
    "\n",
    "# Uncomment this to load data directly from GitHub\n",
    "# DATA_PATH = 'https://raw.githubusercontent.com/richardfoltyn/TECH2-H24/main/data'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Path to Ames housing CSV file\n",
    "fn = f'{DATA_PATH}/ames_houses.csv'\n",
    "\n",
    "# Read in file\n",
    "df = pd.read_csv(fn)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Part (2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Restrict DataFrame to columns used in this exercise\n",
    "df = df[['SalePrice', 'LotArea', 'Bedrooms']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Part (3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop observations with zero bedrooms and small lot areas\n",
    "df = df.query('Bedrooms > 0 & LotArea > 100').copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Part (4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average lot area: 974.0\n"
     ]
    }
   ],
   "source": [
    "# Compute mean lot area\n",
    "mean_area = df['LotArea'].mean()\n",
    "\n",
    "print(f'Average lot area: {mean_area:.1f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We create the `LargeLot` indicator as the result of a logical comparison. Note that this creates a boolean data type, i.e., one with values `True` and `False`. We could additionally convert this column to type `int` to obtain 0's (`False`) and 1's (`True`) instead, but it does not change any of the computations below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LargeLot\n",
       "False     703.521658\n",
       "True     1452.681617\n",
       "Name: LotArea, dtype: float64"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create indicator for whether lot is above average in size (\"large\")\n",
    "df['LargeLot'] = (df['LotArea'] > mean_area)\n",
    "\n",
    "# Alternatively, we can force the column LargeLot to be an integer with 0/1:\n",
    "# df['LargeLot'] = (df['LotArea'] > mean_area).astype(int)\n",
    "\n",
    "# Compute and print average lot size in the large/small categories\n",
    "df.groupby('LargeLot')['LotArea'].mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Part (5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are several ways to recode the `Bedrooms` column into the categories 1, 2, and 3 or more."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Alternative using boolean indexing\n",
    "df['Rooms'] = df['Bedrooms']\n",
    "three_plus = (df['Rooms'] >= 3)\n",
    "# Replace all observations with 3 or more bedrooms with the value 3\n",
    "df.loc[three_plus, 'Rooms'] = 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Alternative using DataFrame.where()\n",
    "df['Rooms'] = df['Bedrooms'].where(df['Bedrooms'] <= 2, 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "# Alternative using np.where()\n",
    "df['Rooms'] = np.where(df['Bedrooms'] <= 2, df['Bedrooms'], 3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can use [`pd.crosstab()`](https://pandas.pydata.org/docs/reference/api/pandas.crosstab.html) to verify that the mapping of rooms worked as intended:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>Rooms</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Bedrooms</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>50</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>358</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>804</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>213</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Rooms      1    2    3\n",
       "Bedrooms              \n",
       "1         50    0    0\n",
       "2          0  358    0\n",
       "3          0    0  804\n",
       "4          0    0  213\n",
       "5          0    0   21\n",
       "6          0    0    7\n",
       "8          0    0    1"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Cross-tabulate the new column Rooms vs. Bedrooms\n",
    "pd.crosstab(df['Bedrooms'], df['Rooms'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Part (6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LargeLot  Rooms\n",
       "False     1        135182.388889\n",
       "          2        144739.841379\n",
       "          3        164034.885572\n",
       "True      1        270825.357143\n",
       "          2        215591.294118\n",
       "          3        222596.090293\n",
       "Name: SalePrice, dtype: float64"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Compute mean house price within each category\n",
    "mean_prices = df.groupby(['LargeLot', 'Rooms'])['SalePrice'].mean()\n",
    "mean_prices"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Part (7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Price diff for 2 vs. 3 bedrooms for small lot: 9,557 USD\n"
     ]
    }
   ],
   "source": [
    "# Difference of average sales price of homes with 2 vs 1 bedrooms for small lot area\n",
    "diff = mean_prices.loc[False, 2] - mean_prices.loc[False, 1]\n",
    "\n",
    "print(f'Price diff for 2 vs. 3 bedrooms for small lot: {diff:,.0f} USD')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Part (8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Price diff for large vs. small lot with 2 bedrooms: 70,851 USD\n"
     ]
    }
   ],
   "source": [
    "# Difference of average sales price of homes with 3 rooms for large vs. small lot area\n",
    "diff = mean_prices.loc[True, 2] - mean_prices.loc[False, 2]\n",
    "\n",
    "print(f'Price diff for large vs. small lot with 2 bedrooms: {diff:,.0f} USD')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "# Exercise: Inflation and unemployment in the US\n",
    "\n",
    "In this exercise, you'll be working with selected macroeconomic variables for the United States reported at monthly frequency obtained from [FRED](https://fred.stlouisfed.org/).\n",
    "The data set starts in 1948 and contains observations for a total of 864 months.\n",
    "\n",
    "1.  Load the data from the file `FRED_monthly.csv` located in the `data/` folder. Print the first 10 observations to get an idea how the data looks like.\n",
    "2.  Keep only the columns `Year`, `Month`, `CPI`, and `UNRATE`. Moreover, perform this analysis only on observations prior to 1970 and drop the rest.\n",
    "3.  Since pandas has great support for time series data, we want to create an index based on observation dates. \n",
    "\n",
    "    -   To this end, use [`to_datetime()`](https://pandas.pydata.org/docs/reference/api/pandas.to_datetime.html) to convert the `Year` and `Month` columns into a date.\n",
    "\n",
    "        *Hint:* `to_datetime()` requires information on Year/Month/Day, so you need to create a `Day` column first and assign it a value of 1.\n",
    "        You can then call `to_datetime()` with the argument `df[['Year', 'Month', 'Day']]` to create the corresponding date.\n",
    "    -   Store the date information in the column `Date`. Delete the columns `Year`, `Month` and `Day` once you are done as these are no longer needed.\n",
    "    -   Set the `Date` column as the index for the `DataFrame` using [`set_index()`](https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.set_index.html).\n",
    "\n",
    "4.  The column `CPI` stores the consumer price index for the US. You may be more familiar with the concept of inflation, which is the percent change of the CPI relative to the previous period. \n",
    "    Create a new column `Inflation` which contains the _annual_ inflation _in percent_ relative to the same month in the previous year by applying \n",
    "    [`pct_change()`](https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.pct_change.html) to the column `CPI`.\n",
    "\n",
    "    *Hints:* \n",
    "    \n",
    "    -   Since this is monthly data, you need to pass the arguments `periods=12` to `pct_change()` to get annual percent changes.\n",
    "    -   You need to multiply the values returned by `pct_change()` by 100 to get percent values.\n",
    "\n",
    "5.  Compute the average unemployment rate (column `UNRATE`) over the whole sample period. Create a new column `UNRATE_HIGH` that contains an indicator whenever the unemployment rate is above its average value (_\"high unemployment period\"_). \n",
    "    -   How many observations fall into the high- and the low-unemployment periods?\n",
    "    -   What is the average unemployment rate in the high- and low-unemployment periods?\n",
    "6.  Compute the average inflation rate for high- and low-unemployment periods. Is there any difference?\n",
    "7.  Use [`resample()`](https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.resample.html) to aggregate\n",
    "    the inflation data to annual frequency and compute the average inflation within each calendar year.\n",
    "\n",
    "    Which are the three years with the highest inflation rates in the sample?\n",
    "\n",
    "    *Hint:* Use the resampling rule `'YE'` when calling `resample()`.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Solution"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Part (1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Uncomment this to use files in the local data/ directory\n",
    "DATA_PATH = '../data'\n",
    "\n",
    "# Uncomment this to load data directly from GitHub\n",
    "# DATA_PATH = 'https://raw.githubusercontent.com/richardfoltyn/TECH2-H24/main/data'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Year</th>\n",
       "      <th>Month</th>\n",
       "      <th>CPI</th>\n",
       "      <th>UNRATE</th>\n",
       "      <th>FEDFUNDS</th>\n",
       "      <th>REALRATE</th>\n",
       "      <th>LFPART</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1948</td>\n",
       "      <td>1</td>\n",
       "      <td>23.7</td>\n",
       "      <td>3.4</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>58.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1948</td>\n",
       "      <td>2</td>\n",
       "      <td>23.7</td>\n",
       "      <td>3.8</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>58.9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1948</td>\n",
       "      <td>3</td>\n",
       "      <td>23.5</td>\n",
       "      <td>4.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>58.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1948</td>\n",
       "      <td>4</td>\n",
       "      <td>23.8</td>\n",
       "      <td>3.9</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>59.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1948</td>\n",
       "      <td>5</td>\n",
       "      <td>24.0</td>\n",
       "      <td>3.5</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>58.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>1948</td>\n",
       "      <td>6</td>\n",
       "      <td>24.2</td>\n",
       "      <td>3.6</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>59.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>1948</td>\n",
       "      <td>7</td>\n",
       "      <td>24.4</td>\n",
       "      <td>3.6</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>59.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>1948</td>\n",
       "      <td>8</td>\n",
       "      <td>24.4</td>\n",
       "      <td>3.9</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>58.9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>1948</td>\n",
       "      <td>9</td>\n",
       "      <td>24.4</td>\n",
       "      <td>3.8</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>58.9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>1948</td>\n",
       "      <td>10</td>\n",
       "      <td>24.3</td>\n",
       "      <td>3.7</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>58.7</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Year  Month   CPI  UNRATE  FEDFUNDS  REALRATE  LFPART\n",
       "0  1948      1  23.7     3.4       NaN       NaN    58.6\n",
       "1  1948      2  23.7     3.8       NaN       NaN    58.9\n",
       "2  1948      3  23.5     4.0       NaN       NaN    58.5\n",
       "3  1948      4  23.8     3.9       NaN       NaN    59.0\n",
       "4  1948      5  24.0     3.5       NaN       NaN    58.3\n",
       "5  1948      6  24.2     3.6       NaN       NaN    59.2\n",
       "6  1948      7  24.4     3.6       NaN       NaN    59.3\n",
       "7  1948      8  24.4     3.9       NaN       NaN    58.9\n",
       "8  1948      9  24.4     3.8       NaN       NaN    58.9\n",
       "9  1948     10  24.3     3.7       NaN       NaN    58.7"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Path to monthly FRED data\n",
    "fn = f'{DATA_PATH}/FRED_monthly.csv'\n",
    "\n",
    "# Read in file\n",
    "df = pd.read_csv(fn)\n",
    "\n",
    "# Print first 10 observations\n",
    "df.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Part (2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Keep only columns of interest for this analysis\n",
    "df = df[['Year', 'Month', 'CPI', 'UNRATE']]\n",
    "\n",
    "# Keep only periods before 1970\n",
    "df = df.query('Year < 1970')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Part (3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>CPI</th>\n",
       "      <th>UNRATE</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Date</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1948-01-01</th>\n",
       "      <td>23.7</td>\n",
       "      <td>3.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1948-02-01</th>\n",
       "      <td>23.7</td>\n",
       "      <td>3.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1948-03-01</th>\n",
       "      <td>23.5</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1948-04-01</th>\n",
       "      <td>23.8</td>\n",
       "      <td>3.9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1948-05-01</th>\n",
       "      <td>24.0</td>\n",
       "      <td>3.5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             CPI  UNRATE\n",
       "Date                    \n",
       "1948-01-01  23.7     3.4\n",
       "1948-02-01  23.7     3.8\n",
       "1948-03-01  23.5     4.0\n",
       "1948-04-01  23.8     3.9\n",
       "1948-05-01  24.0     3.5"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create Day information required by to_datetime(). Since this is monthly data,\n",
    "# the day does not really matter and we simply set it to 1.\n",
    "df['Day'] = 1\n",
    "\n",
    "# Create a date observation from the individual date components\n",
    "df['Date'] = pd.to_datetime(df[['Year', 'Month', 'Day']])\n",
    "\n",
    "# Delete the date component columns\n",
    "df = df.drop(columns=['Year', 'Month', 'Day'])\n",
    "\n",
    "# Set the Date column as the index\n",
    "df = df.set_index('Date')\n",
    "\n",
    "# Print first 5 obs to confirm that things look OK\n",
    "df.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Part (4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>CPI</th>\n",
       "      <th>UNRATE</th>\n",
       "      <th>Inflation</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Date</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1948-01-01</th>\n",
       "      <td>23.7</td>\n",
       "      <td>3.4</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1948-02-01</th>\n",
       "      <td>23.7</td>\n",
       "      <td>3.8</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1948-03-01</th>\n",
       "      <td>23.5</td>\n",
       "      <td>4.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1948-04-01</th>\n",
       "      <td>23.8</td>\n",
       "      <td>3.9</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1948-05-01</th>\n",
       "      <td>24.0</td>\n",
       "      <td>3.5</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1948-06-01</th>\n",
       "      <td>24.2</td>\n",
       "      <td>3.6</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1948-07-01</th>\n",
       "      <td>24.4</td>\n",
       "      <td>3.6</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1948-08-01</th>\n",
       "      <td>24.4</td>\n",
       "      <td>3.9</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1948-09-01</th>\n",
       "      <td>24.4</td>\n",
       "      <td>3.8</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1948-10-01</th>\n",
       "      <td>24.3</td>\n",
       "      <td>3.7</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1948-11-01</th>\n",
       "      <td>24.2</td>\n",
       "      <td>3.8</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1948-12-01</th>\n",
       "      <td>24.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1949-01-01</th>\n",
       "      <td>24.0</td>\n",
       "      <td>4.3</td>\n",
       "      <td>1.265823</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1949-02-01</th>\n",
       "      <td>23.9</td>\n",
       "      <td>4.7</td>\n",
       "      <td>0.843882</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1949-03-01</th>\n",
       "      <td>23.9</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1.702128</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             CPI  UNRATE  Inflation\n",
       "Date                               \n",
       "1948-01-01  23.7     3.4        NaN\n",
       "1948-02-01  23.7     3.8        NaN\n",
       "1948-03-01  23.5     4.0        NaN\n",
       "1948-04-01  23.8     3.9        NaN\n",
       "1948-05-01  24.0     3.5        NaN\n",
       "1948-06-01  24.2     3.6        NaN\n",
       "1948-07-01  24.4     3.6        NaN\n",
       "1948-08-01  24.4     3.9        NaN\n",
       "1948-09-01  24.4     3.8        NaN\n",
       "1948-10-01  24.3     3.7        NaN\n",
       "1948-11-01  24.2     3.8        NaN\n",
       "1948-12-01  24.0     4.0        NaN\n",
       "1949-01-01  24.0     4.3   1.265823\n",
       "1949-02-01  23.9     4.7   0.843882\n",
       "1949-03-01  23.9     5.0   1.702128"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Compute inflation as the percent change of the CPI\n",
    "df['Inflation'] = df['CPI'].pct_change(periods=12) * 100\n",
    "\n",
    "# Print first 15 observations\n",
    "df.head(15)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that the first 12 observations of `Inflation` are missing since it is not possible to compute 12-month percent changes due to missing data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Part (5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average unemployment rate: 4.7%\n"
     ]
    }
   ],
   "source": [
    "# Compute and report average unemployment rate\n",
    "unrate_avg = df['UNRATE'].mean()\n",
    "print(f'Average unemployment rate: {unrate_avg:.1f}%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "UNRATE_HIGH\n",
       "False    141\n",
       "True     123\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create indicator for above-average unemployment rate\n",
    "df['UNRATE_HIGH'] = df['UNRATE'] > unrate_avg\n",
    "\n",
    "# Tabulate number of periods with above and below-average unemployment\n",
    "df['UNRATE_HIGH'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "UNRATE_HIGH\n",
       "False    3.697872\n",
       "True     5.781301\n",
       "Name: UNRATE, dtype: float64"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Tabulate average unemployment rate in high- and low-unemployment periods\n",
    "df.groupby('UNRATE_HIGH')['UNRATE'].mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Part (6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "UNRATE_HIGH\n",
       "False    3.110456\n",
       "True     0.942056\n",
       "Name: Inflation, dtype: float64"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Compute average inflation in high- and low-unemployment periods\n",
    "df.groupby('UNRATE_HIGH')['Inflation'].mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Part (7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Date\n",
       "1951-12-31    7.987456\n",
       "1969-12-31    5.432647\n",
       "1968-12-31    4.241319\n",
       "Name: Inflation, dtype: float64"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create groups based on calendar year\n",
    "groups = df.resample('YE')\n",
    "\n",
    "# Compute average inflation in each year\n",
    "infl_avg = groups['Inflation'].mean()\n",
    "\n",
    "# Sort in descending order and print the three years with highest average inflation\n",
    "infl_avg.sort_values(ascending=False).head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Alternatively, you can perform these actions in one line:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Date\n",
       "1951-12-31    7.987456\n",
       "1969-12-31    5.432647\n",
       "1968-12-31    4.241319\n",
       "Name: Inflation, dtype: float64"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.resample('YE')['Inflation'].mean().sort_values(ascending=False).head(3)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "TECH2",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
