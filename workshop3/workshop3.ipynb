{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exercise: House price levels and dispersion\n",
    "\n",
    "For this exercise, we're using data on around 1,500 observations of house prices and house characteristics from Ames, a small city in Iowa.\n",
    "\n",
    "1. Load the Ames housing data set from `ames_houses.csv` located in the `data/` folder. \n",
    "2. Restrict the data to the columns `SalePrice` and `Neighborhood`.\n",
    "3. Check that there are no observations with missing values in this data.\n",
    "4. Compute the average house price (column `SalePrice`) by neighborhood (column `Neighborhood`). List the three most expensive neighborhoods, for example by using [`sort_values()`](https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.sort_values.html).\n",
    "5. You are interested to quantify the price dispersion in each neighborhood. To this end, compute the standard deviation by neighborhood using [`std()`](https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.std.html). Which are the three neighborhoods with the most dispersed prices?\n",
    "6. An alternative measure of dispersion is the ratio of the 90th and 10th percentile of the house price distribution. Use the [`quantile()`](https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.quantile.html) method to compute the P90 and P10 statistics by neighborhood, compute their ratio and print the three neighborhoods with the largest dispersion.\n",
    "\n",
    "    *Hint:* The `quantile()` function takes _quantiles_ as arguments, i.e., instead of the 90th percentile you need to specify the quantile as 0.9."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "# Exercise: Determinants of house prices\n",
    "\n",
    "For this exercise, we're using data on around 1,500 observations of house prices and house characteristics from Ames, a small city in Iowa.\n",
    "\n",
    "1.  Load the Ames housing data set from `ames_houses.csv` located in the `data/` folder. \n",
    "2.  Restrict the data to the columns `SalePrice`, `LotArea` and `Bedrooms`.\n",
    "3.  Restrict your data set to houses with one or more bedrooms and a lot area of at least 100mÂ².\n",
    "4.  Compute the average lot area. Create a new column `LargeLot` which takes on the value of 1 if the lot area is above the average (_\"large\"_), and 0 otherwise (_\"small\"_). \n",
    "\n",
    "    What is the average lot area within these two categories?\n",
    "5.  Create a new column `Rooms` which categorizes the number of `Bedrooms` into three groups: 1, 2, and 3 or more. You can create these categories using boolean indexing, [`np.where()`](https://numpy.org/doc/2.0/reference/generated/numpy.where.html), pandas's [`where()`](https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.where.html), or some other way.\n",
    "6.  Compute the mean `SalePrice` within each group formed by `LargeLot` and `Rooms` (for a total of 6 different categories) using [`groupby()`](https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.groupby.html).\n",
    "7.  Compute and report the average price difference between 1 and 2 bedrooms for a house with a small lot area.\n",
    "8.  Compute and report the average price difference between a small and a large lot for a house with 2 bedrooms."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "# Exercise: Inflation and unemployment in the US\n",
    "\n",
    "In this exercise, you'll be working with selected macroeconomic variables for the United States reported at monthly frequency obtained from [FRED](https://fred.stlouisfed.org/).\n",
    "The data set starts in 1948 and contains observations for a total of 864 months.\n",
    "\n",
    "1.  Load the data from the file `FRED_monthly.csv` located in the `data/` folder. Print the first 10 observations to get an idea how the data looks like.\n",
    "2.  Keep only the columns `Year`, `Month`, `CPI`, and `UNRATE`. Moreover, perform this analysis only on observations prior to 1970 and drop the rest.\n",
    "3.  Since pandas has great support for time series data, we want to create an index based on observation dates. \n",
    "\n",
    "    -   To this end, use [`to_datetime()`](https://pandas.pydata.org/docs/reference/api/pandas.to_datetime.html) to convert the `Year` and `Month` columns into a date.\n",
    "\n",
    "        *Hint:* `to_datetime()` requires information on Year/Month/Day, so you need to create a `Day` column first and assign it a value of 1.\n",
    "        You can then call `to_datetime()` with the argument `df[['Year', 'Month', 'Day']]` to create the corresponding date.\n",
    "    -   Store the date information in the column `Date`. Delete the columns `Year`, `Month` and `Day` once you are done as these are no longer needed.\n",
    "    -   Set the `Date` column as the index for the `DataFrame` using [`set_index()`](https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.set_index.html).\n",
    "\n",
    "4.  The column `CPI` stores the consumer price index for the US. You may be more familiar with the concept of inflation, which is the percent change of the CPI relative to the previous period. \n",
    "    Create a new column `Inflation` which contains the _annual_ inflation _in percent_ relative to the same month in the previous year by applying \n",
    "    [`pct_change()`](https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.pct_change.html) to the column `CPI`.\n",
    "\n",
    "    *Hints:* \n",
    "    \n",
    "    -   Since this is monthly data, you need to pass the arguments `periods=12` to `pct_change()` to get annual percent changes.\n",
    "    -   You need to multiply the values returned by `pct_change()` by 100 to get percent values.\n",
    "\n",
    "5.  Compute the average unemployment rate (column `UNRATE`) over the whole sample period. Create a new column `UNRATE_HIGH` that contains an indicator whenever the unemployment rate is above its average value (_\"high unemployment period\"_). \n",
    "    -   How many observations fall into the high- and the low-unemployment periods?\n",
    "    -   What is the average unemployment rate in the high- and low-unemployment periods?\n",
    "6.  Compute the average inflation rate for high- and low-unemployment periods. Is there any difference?\n",
    "7.  Use [`resample()`](https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.resample.html) to aggregate\n",
    "    the inflation data to annual frequency and compute the average inflation within each calendar year.\n",
    "\n",
    "    Which are the three years with the highest inflation rates in the sample?\n",
    "\n",
    "    *Hint:* Use the resampling rule `'YE'` when calling `resample()`.\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "TECH2",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
